program: src/train.py
name: grpo_sweep
method: grid
metric:
  goal: maximize
  name: model_eval_val/reward 
parameters:
  grpo_alpha:
    values: [2.0]
  grpo_explore_amplitude:
    values: [0.0, 0.05, 0.1, 0.2]
  grpo_q_function:
    values: [True]
  reward_model_params:
    values: [
      '{"final_position_weight": 1.0, "final_velocity_weight": 0.0, "total_time_weight": 0.0, "pointing_north_weight": 0.0, "wall_contact_weight": 0.0, "control_magnitude_weight": 0.0}',
      '{"final_position_weight": 1.0, "final_velocity_weight": 1.0, "total_time_weight": 0.0, "pointing_north_weight": 0.0, "wall_contact_weight": 0.0, "control_magnitude_weight": 0.0}',
      '{"final_position_weight": 1.0, "final_velocity_weight": 0.0, "total_time_weight": 0.1, "pointing_north_weight": 0.0, "wall_contact_weight": 0.0, "control_magnitude_weight": 0.0}',
      '{"final_position_weight": 1.0, "final_velocity_weight": 0.0, "total_time_weight": 0.0, "pointing_north_weight": 0.5, "wall_contact_weight": 0.0, "control_magnitude_weight": 0.0}',
      '{"final_position_weight": 1.0, "final_velocity_weight": 0.0, "total_time_weight": 0.0, "pointing_north_weight": 0.0, "wall_contact_weight": 1.0, "control_magnitude_weight": 0.0}',
      '{"final_position_weight": 1.0, "final_velocity_weight": 0.0, "total_time_weight": 0.0, "pointing_north_weight": 0.0, "wall_contact_weight": 0.0, "control_magnitude_weight": 0.5}',
    ]
command:
  - ${env}
  - ${interpreter}
  - ${program}
  - --output_dir=./output/ga${grpo_alpha}_gea${grpo_explore_amplitude}_gqf${grpo_q_function}_reward${reward_model_params} 
  - --env=unicycle
  - --model_architecture=unicycle
  - --grpo_start_epoch=200
  - --rwfm_alpha=0.0
  - --wandb_version=grpo_sweep
  - ${args}